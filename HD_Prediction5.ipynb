{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "HD_Prediction5.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devi777/Heart-Disease-Classification/blob/master/HD_Prediction5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2tVdAIAbehV",
        "colab_type": "text"
      },
      "source": [
        "# Pre-processing Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUth6uxEbehW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58G8V4y5beha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing the dataset\n",
        "df = pd.read_csv('heart.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiO7hxEMbehc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.iloc[:,:-1].values\n",
        "y = df.iloc[:,-1].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdlzBfmfbehf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKsTZRjkbehh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RmBwoXYbehk",
        "colab_type": "text"
      },
      "source": [
        "# R-squared "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M18OdcIGbehk",
        "colab_type": "text"
      },
      "source": [
        "To caclulate variance inflation factor, here is the link: https://etav.github.io/python/vif_factor_python.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPMiA0ntbehl",
        "colab_type": "text"
      },
      "source": [
        "Featured snippet from the web\n",
        "\n",
        "\"Pearson Product-Moment Correlation Coefficient. The Excel RSQ Function returns the square of the Pearson product-moment correlation coefficient, which is a statistical measurement of the correlation (linear association) between two sets of values.\"\n",
        "\n",
        "\"R-squared (R2) is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV_sh2oHbehl",
        "colab_type": "raw"
      },
      "source": [
        "(Only for single parameter)\n",
        "correlation_matrix = np.corrcoef(X_train, y_train)\n",
        "correlation_xy = correlation_matrix[0,1]\n",
        "r_squared = correlation_xy**2\n",
        "\n",
        "print(r_squared)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqy-FgUxbehm",
        "colab_type": "text"
      },
      "source": [
        "Forward selection: which involves starting with no variables in the model, testing the addition of each variable using a chosen model fit criterion, adding the variable (if any) whose inclusion gives the most statistically significant improvement of the fit, and repeating this process until none improves the model to a statistically significant extent.\n",
        "\n",
        "Backward elimination: which involves starting with all candidate variables, testing the deletion of each variable using a chosen model fit criterion, deleting the variable (if any) whose loss gives the most statistically insignificant deterioration of the model fit, and repeating this process until no further variables can be deleted without a statistically insignificant loss of fit.\n",
        "\n",
        "Bidirectional elimination: a combination of the above, testing at each step for variables to be included or excluded. \n",
        "\n",
        "So, to select k number of features from a total n no of features , we use feature selection or feature extraction to increase our evaluation speed of model and sometimes to visualize the data as well (k = 2/3 if visualizing). Let's implement feature selection in this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ma4QvOtybehm",
        "colab_type": "text"
      },
      "source": [
        "#  Backward elimination with Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76VwOdspbehn",
        "colab_type": "code",
        "colab": {},
        "outputId": "49e37f93-170a-4e1c-a8fd-c1ca693c4d28"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state=0)\n",
        "classifier.fit(X_train,y_train) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dN7rP7cMbehq",
        "colab_type": "code",
        "colab": {},
        "outputId": "b092cc75-5e11-426a-e629-3735fff99d08"
      },
      "source": [
        "print('Test accuracy {:.2f}%'.format(classifier.score(X_test,y_test)*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy 82.89%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxk-JuCtbeht",
        "colab_type": "code",
        "colab": {},
        "outputId": "ad5a0e22-5e7f-4516-c28d-08bada29644e"
      },
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "print(y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 1 0 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 0 1 1 1 0 1 1 1 1 0\n",
            " 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0\n",
            " 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD1T62eubehv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import statsmodels.regression.linear_model as sm \n",
        "# add a column of ones as integer data type \n",
        "X = np.append(arr = np.ones((303, 1)).astype(int), values = X, axis = 1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcgQ-4Ftbehx",
        "colab_type": "code",
        "colab": {},
        "outputId": "d6379795-b575-49dd-8eea-41d0919ebe5e"
      },
      "source": [
        "# choose a Significance level usually 0.05, if p>0.05 \n",
        "# for the highest values parameter, remove that value \n",
        "X_opt = np.array(X[:, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]], dtype=float)\n",
        "classifier_ols = sm.OLS(endog = y, exog = X_opt).fit() \n",
        "classifier_ols.summary() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.499</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.478</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   24.06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sat, 18 Apr 2020</td> <th>  Prob (F-statistic):</th> <td>5.77e-37</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>13:23:37</td>     <th>  Log-Likelihood:    </th> <td> -114.02</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   303</td>      <th>  AIC:               </th> <td>   254.0</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>   290</td>      <th>  BIC:               </th> <td>   302.3</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>    12</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th> <td>    0.6784</td> <td>    0.294</td> <td>    2.304</td> <td> 0.022</td> <td>    0.099</td> <td>    1.258</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th>    <td>   -0.0010</td> <td>    0.003</td> <td>   -0.357</td> <td> 0.721</td> <td>   -0.006</td> <td>    0.004</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th>    <td>   -0.2275</td> <td>    0.047</td> <td>   -4.841</td> <td> 0.000</td> <td>   -0.320</td> <td>   -0.135</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x3</th>    <td>    0.1181</td> <td>    0.023</td> <td>    5.201</td> <td> 0.000</td> <td>    0.073</td> <td>    0.163</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x4</th>    <td>   -0.0021</td> <td>    0.001</td> <td>   -1.667</td> <td> 0.097</td> <td>   -0.005</td> <td>    0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x5</th>    <td>   -0.0005</td> <td>    0.000</td> <td>   -1.197</td> <td> 0.232</td> <td>   -0.001</td> <td>    0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x6</th>    <td>    0.0283</td> <td>    0.061</td> <td>    0.467</td> <td> 0.641</td> <td>   -0.091</td> <td>    0.148</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x7</th>    <td>    0.0443</td> <td>    0.041</td> <td>    1.091</td> <td> 0.276</td> <td>   -0.036</td> <td>    0.124</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x8</th>    <td>    0.0029</td> <td>    0.001</td> <td>    2.500</td> <td> 0.013</td> <td>    0.001</td> <td>    0.005</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x9</th>    <td>   -0.1614</td> <td>    0.052</td> <td>   -3.104</td> <td> 0.002</td> <td>   -0.264</td> <td>   -0.059</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x10</th>   <td>   -0.0674</td> <td>    0.023</td> <td>   -2.907</td> <td> 0.004</td> <td>   -0.113</td> <td>   -0.022</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x11</th>   <td>    0.0781</td> <td>    0.043</td> <td>    1.811</td> <td> 0.071</td> <td>   -0.007</td> <td>    0.163</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x12</th>   <td>   -0.1059</td> <td>    0.022</td> <td>   -4.776</td> <td> 0.000</td> <td>   -0.150</td> <td>   -0.062</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 7.875</td> <th>  Durbin-Watson:     </th> <td>   0.981</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.019</td> <th>  Jarque-Bera (JB):  </th> <td>   7.857</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.362</td> <th>  Prob(JB):          </th> <td>  0.0197</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 2.685</td> <th>  Cond. No.          </th> <td>4.62e+03</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 4.62e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                      y   R-squared:                       0.499\n",
              "Model:                            OLS   Adj. R-squared:                  0.478\n",
              "Method:                 Least Squares   F-statistic:                     24.06\n",
              "Date:                Sat, 18 Apr 2020   Prob (F-statistic):           5.77e-37\n",
              "Time:                        13:23:37   Log-Likelihood:                -114.02\n",
              "No. Observations:                 303   AIC:                             254.0\n",
              "Df Residuals:                     290   BIC:                             302.3\n",
              "Df Model:                          12                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const          0.6784      0.294      2.304      0.022       0.099       1.258\n",
              "x1            -0.0010      0.003     -0.357      0.721      -0.006       0.004\n",
              "x2            -0.2275      0.047     -4.841      0.000      -0.320      -0.135\n",
              "x3             0.1181      0.023      5.201      0.000       0.073       0.163\n",
              "x4            -0.0021      0.001     -1.667      0.097      -0.005       0.000\n",
              "x5            -0.0005      0.000     -1.197      0.232      -0.001       0.000\n",
              "x6             0.0283      0.061      0.467      0.641      -0.091       0.148\n",
              "x7             0.0443      0.041      1.091      0.276      -0.036       0.124\n",
              "x8             0.0029      0.001      2.500      0.013       0.001       0.005\n",
              "x9            -0.1614      0.052     -3.104      0.002      -0.264      -0.059\n",
              "x10           -0.0674      0.023     -2.907      0.004      -0.113      -0.022\n",
              "x11            0.0781      0.043      1.811      0.071      -0.007       0.163\n",
              "x12           -0.1059      0.022     -4.776      0.000      -0.150      -0.062\n",
              "==============================================================================\n",
              "Omnibus:                        7.875   Durbin-Watson:                   0.981\n",
              "Prob(Omnibus):                  0.019   Jarque-Bera (JB):                7.857\n",
              "Skew:                          -0.362   Prob(JB):                       0.0197\n",
              "Kurtosis:                       2.685   Cond. No.                     4.62e+03\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The condition number is large, 4.62e+03. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly90gAMTbeh2",
        "colab_type": "text"
      },
      "source": [
        "So, now we need to keep removing the feature columns whose p-value is greater than 0.05 (taken by standard convention)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYYZsBcgbeh2",
        "colab_type": "code",
        "colab": {},
        "outputId": "bcb26bac-9750-4176-825f-53b29a56757d"
      },
      "source": [
        "#Removing 1st Feature\n",
        "X_opt = np.array(X[:, [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]], dtype=float)\n",
        "classifier_ols = sm.OLS(endog = y, exog = X_opt).fit() \n",
        "classifier_ols.summary() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.499</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.480</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   26.32</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sat, 18 Apr 2020</td> <th>  Prob (F-statistic):</th> <td>1.16e-37</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>13:41:07</td>     <th>  Log-Likelihood:    </th> <td> -114.08</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   303</td>      <th>  AIC:               </th> <td>   252.2</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>   291</td>      <th>  BIC:               </th> <td>   296.7</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th> <td>    0.6228</td> <td>    0.250</td> <td>    2.494</td> <td> 0.013</td> <td>    0.131</td> <td>    1.114</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th>    <td>   -0.2258</td> <td>    0.047</td> <td>   -4.837</td> <td> 0.000</td> <td>   -0.318</td> <td>   -0.134</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th>    <td>    0.1177</td> <td>    0.023</td> <td>    5.198</td> <td> 0.000</td> <td>    0.073</td> <td>    0.162</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x3</th>    <td>   -0.0022</td> <td>    0.001</td> <td>   -1.796</td> <td> 0.074</td> <td>   -0.005</td> <td>    0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x4</th>    <td>   -0.0005</td> <td>    0.000</td> <td>   -1.280</td> <td> 0.202</td> <td>   -0.001</td> <td>    0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x5</th>    <td>    0.0269</td> <td>    0.060</td> <td>    0.446</td> <td> 0.656</td> <td>   -0.092</td> <td>    0.146</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x6</th>    <td>    0.0451</td> <td>    0.040</td> <td>    1.114</td> <td> 0.266</td> <td>   -0.035</td> <td>    0.125</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x7</th>    <td>    0.0030</td> <td>    0.001</td> <td>    2.836</td> <td> 0.005</td> <td>    0.001</td> <td>    0.005</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x8</th>    <td>   -0.1600</td> <td>    0.052</td> <td>   -3.091</td> <td> 0.002</td> <td>   -0.262</td> <td>   -0.058</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x9</th>    <td>   -0.0677</td> <td>    0.023</td> <td>   -2.925</td> <td> 0.004</td> <td>   -0.113</td> <td>   -0.022</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x10</th>   <td>    0.0778</td> <td>    0.043</td> <td>    1.806</td> <td> 0.072</td> <td>   -0.007</td> <td>    0.162</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x11</th>   <td>   -0.1074</td> <td>    0.022</td> <td>   -4.940</td> <td> 0.000</td> <td>   -0.150</td> <td>   -0.065</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 8.140</td> <th>  Durbin-Watson:     </th> <td>   0.979</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.017</td> <th>  Jarque-Bera (JB):  </th> <td>   8.148</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.370</td> <th>  Prob(JB):          </th> <td>  0.0170</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 2.686</td> <th>  Cond. No.          </th> <td>3.87e+03</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.87e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                      y   R-squared:                       0.499\n",
              "Model:                            OLS   Adj. R-squared:                  0.480\n",
              "Method:                 Least Squares   F-statistic:                     26.32\n",
              "Date:                Sat, 18 Apr 2020   Prob (F-statistic):           1.16e-37\n",
              "Time:                        13:41:07   Log-Likelihood:                -114.08\n",
              "No. Observations:                 303   AIC:                             252.2\n",
              "Df Residuals:                     291   BIC:                             296.7\n",
              "Df Model:                          11                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const          0.6228      0.250      2.494      0.013       0.131       1.114\n",
              "x1            -0.2258      0.047     -4.837      0.000      -0.318      -0.134\n",
              "x2             0.1177      0.023      5.198      0.000       0.073       0.162\n",
              "x3            -0.0022      0.001     -1.796      0.074      -0.005       0.000\n",
              "x4            -0.0005      0.000     -1.280      0.202      -0.001       0.000\n",
              "x5             0.0269      0.060      0.446      0.656      -0.092       0.146\n",
              "x6             0.0451      0.040      1.114      0.266      -0.035       0.125\n",
              "x7             0.0030      0.001      2.836      0.005       0.001       0.005\n",
              "x8            -0.1600      0.052     -3.091      0.002      -0.262      -0.058\n",
              "x9            -0.0677      0.023     -2.925      0.004      -0.113      -0.022\n",
              "x10            0.0778      0.043      1.806      0.072      -0.007       0.162\n",
              "x11           -0.1074      0.022     -4.940      0.000      -0.150      -0.065\n",
              "==============================================================================\n",
              "Omnibus:                        8.140   Durbin-Watson:                   0.979\n",
              "Prob(Omnibus):                  0.017   Jarque-Bera (JB):                8.148\n",
              "Skew:                          -0.370   Prob(JB):                       0.0170\n",
              "Kurtosis:                       2.686   Cond. No.                     3.87e+03\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The condition number is large, 3.87e+03. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zONaA5Pbeh4",
        "colab_type": "code",
        "colab": {},
        "outputId": "96366426-4755-4e3f-9be6-f5f8aa5eabcc"
      },
      "source": [
        "#Removing 6th Feature\n",
        "X_opt = np.array(X[:, [0, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12]], dtype=float)\n",
        "classifier_ols = sm.OLS(endog = y, exog = X_opt).fit() \n",
        "classifier_ols.summary() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.498</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.481</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   29.01</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sat, 18 Apr 2020</td> <th>  Prob (F-statistic):</th> <td>2.31e-38</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>13:42:14</td>     <th>  Log-Likelihood:    </th> <td> -114.19</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   303</td>      <th>  AIC:               </th> <td>   250.4</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>   292</td>      <th>  BIC:               </th> <td>   291.2</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th> <td>    0.6150</td> <td>    0.249</td> <td>    2.472</td> <td> 0.014</td> <td>    0.125</td> <td>    1.105</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th>    <td>   -0.2250</td> <td>    0.047</td> <td>   -4.830</td> <td> 0.000</td> <td>   -0.317</td> <td>   -0.133</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th>    <td>    0.1189</td> <td>    0.022</td> <td>    5.295</td> <td> 0.000</td> <td>    0.075</td> <td>    0.163</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x3</th>    <td>   -0.0021</td> <td>    0.001</td> <td>   -1.750</td> <td> 0.081</td> <td>   -0.005</td> <td>    0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x4</th>    <td>   -0.0005</td> <td>    0.000</td> <td>   -1.284</td> <td> 0.200</td> <td>   -0.001</td> <td>    0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x5</th>    <td>    0.0441</td> <td>    0.040</td> <td>    1.093</td> <td> 0.275</td> <td>   -0.035</td> <td>    0.123</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x6</th>    <td>    0.0030</td> <td>    0.001</td> <td>    2.847</td> <td> 0.005</td> <td>    0.001</td> <td>    0.005</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x7</th>    <td>   -0.1589</td> <td>    0.052</td> <td>   -3.078</td> <td> 0.002</td> <td>   -0.261</td> <td>   -0.057</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x8</th>    <td>   -0.0686</td> <td>    0.023</td> <td>   -2.980</td> <td> 0.003</td> <td>   -0.114</td> <td>   -0.023</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x9</th>    <td>    0.0763</td> <td>    0.043</td> <td>    1.780</td> <td> 0.076</td> <td>   -0.008</td> <td>    0.161</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x10</th>   <td>   -0.1060</td> <td>    0.021</td> <td>   -4.934</td> <td> 0.000</td> <td>   -0.148</td> <td>   -0.064</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 8.432</td> <th>  Durbin-Watson:     </th> <td>   0.980</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.015</td> <th>  Jarque-Bera (JB):  </th> <td>   8.493</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.380</td> <th>  Prob(JB):          </th> <td>  0.0143</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 2.693</td> <th>  Cond. No.          </th> <td>3.86e+03</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.86e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                      y   R-squared:                       0.498\n",
              "Model:                            OLS   Adj. R-squared:                  0.481\n",
              "Method:                 Least Squares   F-statistic:                     29.01\n",
              "Date:                Sat, 18 Apr 2020   Prob (F-statistic):           2.31e-38\n",
              "Time:                        13:42:14   Log-Likelihood:                -114.19\n",
              "No. Observations:                 303   AIC:                             250.4\n",
              "Df Residuals:                     292   BIC:                             291.2\n",
              "Df Model:                          10                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const          0.6150      0.249      2.472      0.014       0.125       1.105\n",
              "x1            -0.2250      0.047     -4.830      0.000      -0.317      -0.133\n",
              "x2             0.1189      0.022      5.295      0.000       0.075       0.163\n",
              "x3            -0.0021      0.001     -1.750      0.081      -0.005       0.000\n",
              "x4            -0.0005      0.000     -1.284      0.200      -0.001       0.000\n",
              "x5             0.0441      0.040      1.093      0.275      -0.035       0.123\n",
              "x6             0.0030      0.001      2.847      0.005       0.001       0.005\n",
              "x7            -0.1589      0.052     -3.078      0.002      -0.261      -0.057\n",
              "x8            -0.0686      0.023     -2.980      0.003      -0.114      -0.023\n",
              "x9             0.0763      0.043      1.780      0.076      -0.008       0.161\n",
              "x10           -0.1060      0.021     -4.934      0.000      -0.148      -0.064\n",
              "==============================================================================\n",
              "Omnibus:                        8.432   Durbin-Watson:                   0.980\n",
              "Prob(Omnibus):                  0.015   Jarque-Bera (JB):                8.493\n",
              "Skew:                          -0.380   Prob(JB):                       0.0143\n",
              "Kurtosis:                       2.693   Cond. No.                     3.86e+03\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The condition number is large, 3.86e+03. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LuKkHU1beh6",
        "colab_type": "code",
        "colab": {},
        "outputId": "8566da85-83c1-404c-e0d9-50384d9211c4"
      },
      "source": [
        "#Removing 7th feature\n",
        "X_opt = np.array(X[:, [0, 2, 3, 4, 5, 8, 9, 10, 11, 12]], dtype=float)\n",
        "classifier_ols = sm.OLS(endog = y, exog = X_opt).fit() \n",
        "classifier_ols.summary() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.496</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.481</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   32.08</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sat, 18 Apr 2020</td> <th>  Prob (F-statistic):</th> <td>7.06e-39</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>13:44:35</td>     <th>  Log-Likelihood:    </th> <td> -114.80</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   303</td>      <th>  AIC:               </th> <td>   249.6</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>   293</td>      <th>  BIC:               </th> <td>   286.7</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th> <td>    0.6702</td> <td>    0.244</td> <td>    2.750</td> <td> 0.006</td> <td>    0.191</td> <td>    1.150</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th>    <td>   -0.2293</td> <td>    0.046</td> <td>   -4.939</td> <td> 0.000</td> <td>   -0.321</td> <td>   -0.138</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th>    <td>    0.1192</td> <td>    0.022</td> <td>    5.308</td> <td> 0.000</td> <td>    0.075</td> <td>    0.163</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x3</th>    <td>   -0.0023</td> <td>    0.001</td> <td>   -1.857</td> <td> 0.064</td> <td>   -0.005</td> <td>    0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x4</th>    <td>   -0.0006</td> <td>    0.000</td> <td>   -1.464</td> <td> 0.144</td> <td>   -0.001</td> <td>    0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x5</th>    <td>    0.0030</td> <td>    0.001</td> <td>    2.837</td> <td> 0.005</td> <td>    0.001</td> <td>    0.005</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x6</th>    <td>   -0.1601</td> <td>    0.052</td> <td>   -3.099</td> <td> 0.002</td> <td>   -0.262</td> <td>   -0.058</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x7</th>    <td>   -0.0676</td> <td>    0.023</td> <td>   -2.940</td> <td> 0.004</td> <td>   -0.113</td> <td>   -0.022</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x8</th>    <td>    0.0800</td> <td>    0.043</td> <td>    1.871</td> <td> 0.062</td> <td>   -0.004</td> <td>    0.164</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x9</th>    <td>   -0.1069</td> <td>    0.021</td> <td>   -4.980</td> <td> 0.000</td> <td>   -0.149</td> <td>   -0.065</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 7.873</td> <th>  Durbin-Watson:     </th> <td>   0.983</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.020</td> <th>  Jarque-Bera (JB):  </th> <td>   7.961</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.370</td> <th>  Prob(JB):          </th> <td>  0.0187</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 2.710</td> <th>  Cond. No.          </th> <td>3.78e+03</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.78e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                      y   R-squared:                       0.496\n",
              "Model:                            OLS   Adj. R-squared:                  0.481\n",
              "Method:                 Least Squares   F-statistic:                     32.08\n",
              "Date:                Sat, 18 Apr 2020   Prob (F-statistic):           7.06e-39\n",
              "Time:                        13:44:35   Log-Likelihood:                -114.80\n",
              "No. Observations:                 303   AIC:                             249.6\n",
              "Df Residuals:                     293   BIC:                             286.7\n",
              "Df Model:                           9                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const          0.6702      0.244      2.750      0.006       0.191       1.150\n",
              "x1            -0.2293      0.046     -4.939      0.000      -0.321      -0.138\n",
              "x2             0.1192      0.022      5.308      0.000       0.075       0.163\n",
              "x3            -0.0023      0.001     -1.857      0.064      -0.005       0.000\n",
              "x4            -0.0006      0.000     -1.464      0.144      -0.001       0.000\n",
              "x5             0.0030      0.001      2.837      0.005       0.001       0.005\n",
              "x6            -0.1601      0.052     -3.099      0.002      -0.262      -0.058\n",
              "x7            -0.0676      0.023     -2.940      0.004      -0.113      -0.022\n",
              "x8             0.0800      0.043      1.871      0.062      -0.004       0.164\n",
              "x9            -0.1069      0.021     -4.980      0.000      -0.149      -0.065\n",
              "==============================================================================\n",
              "Omnibus:                        7.873   Durbin-Watson:                   0.983\n",
              "Prob(Omnibus):                  0.020   Jarque-Bera (JB):                7.961\n",
              "Skew:                          -0.370   Prob(JB):                       0.0187\n",
              "Kurtosis:                       2.710   Cond. No.                     3.78e+03\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The condition number is large, 3.78e+03. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R37cRooebeh9",
        "colab_type": "code",
        "colab": {},
        "outputId": "79fd78d0-86b5-4ae1-ea4d-5966586c67e0"
      },
      "source": [
        "#Removing 5th feature\n",
        "X_opt = np.array(X[:, [0, 2, 3, 4, 8, 9, 10, 11, 12]], dtype=float)\n",
        "classifier_ols = sm.OLS(endog = y, exog = X_opt).fit() \n",
        "classifier_ols.summary() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.493</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.479</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   35.68</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sat, 18 Apr 2020</td> <th>  Prob (F-statistic):</th> <td>3.23e-39</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>13:46:34</td>     <th>  Log-Likelihood:    </th> <td> -115.91</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   303</td>      <th>  AIC:               </th> <td>   249.8</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>   294</td>      <th>  BIC:               </th> <td>   283.2</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th> <td>    0.5499</td> <td>    0.230</td> <td>    2.392</td> <td> 0.017</td> <td>    0.098</td> <td>    1.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th>    <td>   -0.2148</td> <td>    0.045</td> <td>   -4.727</td> <td> 0.000</td> <td>   -0.304</td> <td>   -0.125</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th>    <td>    0.1211</td> <td>    0.022</td> <td>    5.392</td> <td> 0.000</td> <td>    0.077</td> <td>    0.165</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x3</th>    <td>   -0.0024</td> <td>    0.001</td> <td>   -2.010</td> <td> 0.045</td> <td>   -0.005</td> <td>-5.05e-05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x4</th>    <td>    0.0030</td> <td>    0.001</td> <td>    2.775</td> <td> 0.006</td> <td>    0.001</td> <td>    0.005</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x5</th>    <td>   -0.1649</td> <td>    0.052</td> <td>   -3.193</td> <td> 0.002</td> <td>   -0.267</td> <td>   -0.063</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x6</th>    <td>   -0.0690</td> <td>    0.023</td> <td>   -2.998</td> <td> 0.003</td> <td>   -0.114</td> <td>   -0.024</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x7</th>    <td>    0.0777</td> <td>    0.043</td> <td>    1.815</td> <td> 0.071</td> <td>   -0.007</td> <td>    0.162</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x8</th>    <td>   -0.1090</td> <td>    0.021</td> <td>   -5.078</td> <td> 0.000</td> <td>   -0.151</td> <td>   -0.067</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 7.839</td> <th>  Durbin-Watson:     </th> <td>   0.975</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.020</td> <th>  Jarque-Bera (JB):  </th> <td>   8.080</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.383</td> <th>  Prob(JB):          </th> <td>  0.0176</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 2.771</td> <th>  Cond. No.          </th> <td>2.23e+03</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.23e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                      y   R-squared:                       0.493\n",
              "Model:                            OLS   Adj. R-squared:                  0.479\n",
              "Method:                 Least Squares   F-statistic:                     35.68\n",
              "Date:                Sat, 18 Apr 2020   Prob (F-statistic):           3.23e-39\n",
              "Time:                        13:46:34   Log-Likelihood:                -115.91\n",
              "No. Observations:                 303   AIC:                             249.8\n",
              "Df Residuals:                     294   BIC:                             283.2\n",
              "Df Model:                           8                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const          0.5499      0.230      2.392      0.017       0.098       1.002\n",
              "x1            -0.2148      0.045     -4.727      0.000      -0.304      -0.125\n",
              "x2             0.1211      0.022      5.392      0.000       0.077       0.165\n",
              "x3            -0.0024      0.001     -2.010      0.045      -0.005   -5.05e-05\n",
              "x4             0.0030      0.001      2.775      0.006       0.001       0.005\n",
              "x5            -0.1649      0.052     -3.193      0.002      -0.267      -0.063\n",
              "x6            -0.0690      0.023     -2.998      0.003      -0.114      -0.024\n",
              "x7             0.0777      0.043      1.815      0.071      -0.007       0.162\n",
              "x8            -0.1090      0.021     -5.078      0.000      -0.151      -0.067\n",
              "==============================================================================\n",
              "Omnibus:                        7.839   Durbin-Watson:                   0.975\n",
              "Prob(Omnibus):                  0.020   Jarque-Bera (JB):                8.080\n",
              "Skew:                          -0.383   Prob(JB):                       0.0176\n",
              "Kurtosis:                       2.771   Cond. No.                     2.23e+03\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The condition number is large, 2.23e+03. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEIKOQTWbeh_",
        "colab_type": "code",
        "colab": {},
        "outputId": "cf58e43d-9e04-477a-dea9-c5933333dd07"
      },
      "source": [
        "#Removing 11th feature\n",
        "X_opt = np.array(X[:, [0, 2, 3, 4, 8, 9, 10, 12]], dtype=float)\n",
        "classifier_ols = sm.OLS(endog = y, exog = X_opt).fit() \n",
        "classifier_ols.summary() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.487</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.475</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   40.00</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sat, 18 Apr 2020</td> <th>  Prob (F-statistic):</th> <td>2.44e-39</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>13:49:55</td>     <th>  Log-Likelihood:    </th> <td> -117.60</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   303</td>      <th>  AIC:               </th> <td>   251.2</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>   295</td>      <th>  BIC:               </th> <td>   280.9</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th> <td>    0.6164</td> <td>    0.228</td> <td>    2.706</td> <td> 0.007</td> <td>    0.168</td> <td>    1.065</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th>    <td>   -0.2124</td> <td>    0.046</td> <td>   -4.658</td> <td> 0.000</td> <td>   -0.302</td> <td>   -0.123</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th>    <td>    0.1200</td> <td>    0.023</td> <td>    5.324</td> <td> 0.000</td> <td>    0.076</td> <td>    0.164</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x3</th>    <td>   -0.0025</td> <td>    0.001</td> <td>   -2.036</td> <td> 0.043</td> <td>   -0.005</td> <td>-8.33e-05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x4</th>    <td>    0.0034</td> <td>    0.001</td> <td>    3.279</td> <td> 0.001</td> <td>    0.001</td> <td>    0.005</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x5</th>    <td>   -0.1700</td> <td>    0.052</td> <td>   -3.283</td> <td> 0.001</td> <td>   -0.272</td> <td>   -0.068</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x6</th>    <td>   -0.0900</td> <td>    0.020</td> <td>   -4.504</td> <td> 0.000</td> <td>   -0.129</td> <td>   -0.051</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x7</th>    <td>   -0.1053</td> <td>    0.021</td> <td>   -4.908</td> <td> 0.000</td> <td>   -0.147</td> <td>   -0.063</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 8.461</td> <th>  Durbin-Watson:     </th> <td>   0.966</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.015</td> <th>  Jarque-Bera (JB):  </th> <td>   8.749</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.400</td> <th>  Prob(JB):          </th> <td>  0.0126</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 2.767</td> <th>  Cond. No.          </th> <td>2.20e+03</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.2e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                      y   R-squared:                       0.487\n",
              "Model:                            OLS   Adj. R-squared:                  0.475\n",
              "Method:                 Least Squares   F-statistic:                     40.00\n",
              "Date:                Sat, 18 Apr 2020   Prob (F-statistic):           2.44e-39\n",
              "Time:                        13:49:55   Log-Likelihood:                -117.60\n",
              "No. Observations:                 303   AIC:                             251.2\n",
              "Df Residuals:                     295   BIC:                             280.9\n",
              "Df Model:                           7                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const          0.6164      0.228      2.706      0.007       0.168       1.065\n",
              "x1            -0.2124      0.046     -4.658      0.000      -0.302      -0.123\n",
              "x2             0.1200      0.023      5.324      0.000       0.076       0.164\n",
              "x3            -0.0025      0.001     -2.036      0.043      -0.005   -8.33e-05\n",
              "x4             0.0034      0.001      3.279      0.001       0.001       0.005\n",
              "x5            -0.1700      0.052     -3.283      0.001      -0.272      -0.068\n",
              "x6            -0.0900      0.020     -4.504      0.000      -0.129      -0.051\n",
              "x7            -0.1053      0.021     -4.908      0.000      -0.147      -0.063\n",
              "==============================================================================\n",
              "Omnibus:                        8.461   Durbin-Watson:                   0.966\n",
              "Prob(Omnibus):                  0.015   Jarque-Bera (JB):                8.749\n",
              "Skew:                          -0.400   Prob(JB):                       0.0126\n",
              "Kurtosis:                       2.767   Cond. No.                     2.20e+03\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The condition number is large, 2.2e+03. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7jLSLH8beiB",
        "colab_type": "text"
      },
      "source": [
        "So, we have selected all the features which have significance less than 5%. Let's fit it to the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb7Y5-CzbeiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_opt, y, test_size = 0.25, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qurxtxoMbeiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgRw4FiebeiG",
        "colab_type": "code",
        "colab": {},
        "outputId": "bb71e528-9767-48fa-bf70-927dc2609fac"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state=0)\n",
        "classifier.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTGlIFXKbeiI",
        "colab_type": "code",
        "colab": {},
        "outputId": "69c3edfd-e1bd-4bb3-9d28-09f5aa6fdd9f"
      },
      "source": [
        "print('Test accuracy {:.2f}%'.format(classifier.score(X_test,y_test)*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy 78.95%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKy-XApYbeiK",
        "colab_type": "text"
      },
      "source": [
        "This happened because the R-squared and Adjusted R-squared values decreased after removing 5th feature, showing the performance of model has reduced. Let's try the model on the peak Adjusted R-squared value, i.e., when we removed the 6th feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRWF30hXbeiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_opt = np.array(X[:, [0, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12]], dtype=float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8Fg3cMXbeiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_opt, y, test_size = 0.25, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKP57lpIbeiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhw_sZpZbeiR",
        "colab_type": "code",
        "colab": {},
        "outputId": "1eb05125-3263-4b51-c053-09d44e22ce3a"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state=0)\n",
        "classifier.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8t4K2tubeiU",
        "colab_type": "code",
        "colab": {},
        "outputId": "7d9d8833-e977-4005-dd28-3b77714356d6"
      },
      "source": [
        "print('Test accuracy {:.2f}%'.format(classifier.score(X_test,y_test)*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy 80.26%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIByCMj8beiW",
        "colab_type": "text"
      },
      "source": [
        "Better, but not upto the mark. Obviously, we are applying Backward elimination to a Classification dataset. But, we were successful in implementing it :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnJJWE9wbeiW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}